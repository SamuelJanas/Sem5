batch_size: 128
lr: 2e-4
epochs: 9

device: 'cuda:0'

hidden_size: 128
num_layers: 2
num_classes: 5 
dropout: 0.2