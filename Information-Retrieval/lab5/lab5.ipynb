{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 5: PageRank, TrustRank, HITS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before you start\n",
    "\n",
    "- Notebook tasks can be completed individually or in a group of two\n",
    "- Please save your notebooks with filled cell outputs; this will speed up the checking process\n",
    "- Send notebook with solutions via e-mail:\n",
    "  - To: michal.wojcik@doctorate.put.poznan.pl\n",
    "  - Subject format example: [IR] Lab 5 - Jan Kowalski 123456, Anna Nowak 789012\n",
    "  - Attachment: notebook file\n",
    "- **Deadline:** 14 days after the class\n",
    "- Some of the tasks require implementation - complete the code\n",
    "- Some of the tasks require answering questions - answer them in Markdowns (just below the questions)\n",
    "- The number of points for each task is given next to the command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - graphs definition [4p]\n",
    "\n",
    "Prepare some graphs with the *networkx* library as described. Show:\n",
    "- list of nodes\n",
    "- adjacency matrix\n",
    "- draw a graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) *Random* graph: [1p]**\n",
    "\n",
    "Create directed graph ([nx.DiGraph](https://networkx.org/documentation/stable/reference/classes/digraph.html)) with:\n",
    "  - 10 nodes\n",
    "  - 25 edges (generated randomly or manually; self-loops are possible but not required)\n",
    "  - *connected* (according to the default concept of conectivity - there is at least one path connecting each pair of nodes; let's additionally assume that not all of the paths need to be *directed*)\n",
    "\n",
    "**NOTE:** set the random seed so that the graph is reproducible or declare the edges manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G_random = ...\n",
    "\n",
    "print(G_random.nodes)\n",
    "print(nx.adjacency_matrix(G_random).todense())\n",
    "nx.draw(G_random, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) *Spider-trap* graph: [1p]**\n",
    "\n",
    "Create directed graph with:\n",
    "- at least 5 nodes\n",
    "- at least 2 nodes in *spider-trap(s)* (two separate *traps* or one *trap* with two nodes)\n",
    "\n",
    "**NOTE:** declare the edges manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G_spider_trap = ...\n",
    "\n",
    "print(G_spider_trap.nodes)\n",
    "print(nx.adjacency_matrix(G_spider_trap).todense())\n",
    "nx.draw(G_spider_trap, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) *Dead-end* graph: [1p]**\n",
    "\n",
    "Create directed graph with:\n",
    "- at least 5 nodes\n",
    "- 1 or 2 nodes as a *dead-end(s)*\n",
    "\n",
    "**NOTE:** declare the edges manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G_dead_end = ...\n",
    "\n",
    "print(G_dead_end.nodes)\n",
    "print(nx.adjacency_matrix(G_dead_end).todense())\n",
    "nx.draw(G_dead_end, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d) *Complete* graph: [1p]**\n",
    "\n",
    "Create directed graph with:\n",
    "- at least 5 nodes (**Hint:** 8 is drawn nicely)\n",
    "- connection for every pair of distinct nodes (in both directions)\n",
    "\n",
    "**NOTE:** declare the edges manually or use a dedicated method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# G_complete = ...\n",
    "\n",
    "print(G_complete.nodes)\n",
    "print(nx.adjacency_matrix(G_complete).todense())\n",
    "nx.draw(G_complete, with_labels=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - PageRank algorithm implementation [10p]\n",
    "\n",
    "Implement two approaches to the PageRank algorithm.\n",
    "\n",
    "Below is a reference function from the *networkx* package to verify the operation of the implemented functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def networkx_pagerank(graph: nx.DiGraph, alpha: float = 0.85) -> list:\n",
    "    # graph - NetworkX Graph\n",
    "    # alpha - damping parameter (opposite to damping factor from the lecture presentation)\n",
    "    \n",
    "    # PageRank by NetworkX library\n",
    "    pagerank = nx.pagerank(graph, alpha=alpha)\n",
    "\n",
    "    # Sort dictionary by PageRank value\n",
    "    pagerank_sorted = sorted(pagerank.items(), key=lambda v:(v[1],v[0]), reverse=True)\n",
    "    return pagerank_sorted\n",
    "\n",
    "networkx_pagerank(G_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) *Random walk* approach [5p]**\n",
    "\n",
    "Create a function that will estimate the PageRank value for each node in the graph using the \"Random walk\" strategy\n",
    "\n",
    "- Randomly select start node\n",
    "- In each iteration, with probability equal to:\n",
    "  - $\\alpha$ - go to one of the next nodes in the graph - randomly select one of the successors with equal probability\n",
    "  - $1 - \\alpha$ - go to a random node in the graph - simulate a situation when a user starts browsing from a new, randomly selected page\n",
    "- If the algorithm reaches a *dead end*, go to a random node in the graph\n",
    "- Count the occurrences of each node on the random walk (and normalize at the end to 1)\n",
    "- Return the result in the same way as the *networkx_pagerank* function - a list of tuples sorted in descending order of PageRank values: (node_name, node_pagerank_value)\n",
    "- Verify the method for different *alpha* values and graphs (random graph, dead end, spider trap, complete graph)\n",
    "\n",
    "**NOTE:** for the sake of randomness, this result will be an approximation, but won't be exactly the same as in the *networkx_pagerank* function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomwalk_pagerank(graph: nx.DiGraph, alpha: float = 0.85) -> list:\n",
    "#     ...\n",
    "\n",
    "randomwalk_pagerank(G_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) *Stochastic matrix* approach [5p]**\n",
    "\n",
    "Create a function that will estimate the PageRank value for each of $N$ nodes in the graph using the stochastic adjacency matrix: $v = Mv$.\n",
    "\n",
    "Using the damping parameter, in order to ensure normalization after each step, the formula changes as follows: $v = (1 - \\alpha) \\cdot v_{\\text{start}} + \\alpha \\cdot Mv$, where $v_{\\text{start}} = [\\frac{1}{N}, \\frac{1}{N}, \\ldots, \\frac{1}{N}]$.\n",
    "\n",
    "- Start with $v = v_{\\text{start}}$\n",
    "- Normalize the adjacency matrix ($M$) so that each cell ($m_{ij}$) in the matrix determines the probability of going from $\\text{node}_i$ to $\\text{node}_j$\n",
    "- At each iteration, update $v$ with a new vector $v' = (1 - \\alpha) \\cdot v_{\\text{start}} + \\alpha \\cdot Mv$\n",
    "- Stop the algorithm when the difference between each pair of the PageRank values for the same node in consecutive $v$ and $v'$ vectors is less than the *epsilon* parameter\n",
    "- Return the result in the same way as the *networkx_pagerank* function - a list of tuples sorted in descending order of PageRank values: (node_name, node_pagerank_value)\n",
    "- Verify the method for different alpha values and graphs (random graph, dead end, spider trap, complete graph)\n",
    "\n",
    "**Hint:** in the case of *dead ends* it is necessary to modify the values in the matrix to simulate the same policy as in the *random walk* approach (*go to a random node*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_matrix_pagerank(graph: nx.DiGraph, alpha: float = 0.85, epsilon: float = 0.0000001) -> list:\n",
    "#     ...\n",
    "\n",
    "stochastic_matrix_pagerank(G_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the functions\n",
    "\n",
    "**NOTE:** For some graphs, *networkx_pagerank* may have trouble generating results with $\\alpha$ close to 1; in this case, note it and skip displaying this result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "names = ['G_random', 'G_spider_trap', 'G_dead_end', 'G_complete']\n",
    "graphs = [G_random, G_spider_trap, G_dead_end, G_complete]\n",
    "\n",
    "for name, graph in zip(names, graphs):\n",
    "    print(\"==================\")\n",
    "    print(\"GRAPH_NAME:\", name)\n",
    "    \n",
    "    nx.draw(graph, with_labels=True)\n",
    "    plt.show()\n",
    "    \n",
    "    for alpha in [0.25, 0.5, 0.7, 0.85, 1.0]:\n",
    "        print('ALPHA:', alpha)\n",
    "        \n",
    "        nx_result = networkx_pagerank(graph, alpha)\n",
    "        rw_result = randomwalk_pagerank(graph, alpha)\n",
    "        sm_result = stochastic_matrix_pagerank(graph, alpha)\n",
    "        \n",
    "        for nx_node, rw_node, sm_node in zip(nx_result, rw_result, sm_result):\n",
    "            print(nx_node, rw_node, sm_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Catan fandom Wikipedia\n",
    "\n",
    "The scripts used for scraping are in the *scraper.ipynb* file.\n",
    "\n",
    "Pages from Fandom Wikipedia: https://catan.fandom.com/wiki/Main_Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('catan_links.pickle', 'rb') as handle:\n",
    "    d = pickle.load(handle)\n",
    "\n",
    "G_catan = nx.DiGraph(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G_catan, with_labels=True, node_size=60, font_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "catan_pr = networkx_pagerank(G_catan)\n",
    "catan_pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review example subgraph\n",
    "\n",
    "**NOTE:** the ranking of pages in different subset of pages may differ significantly from the original, e.g. */wiki/Catan:_Traders_%26_Barbarians* which had the third highest PageRank value in the original graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "number_of_pages = 20\n",
    "pages_with_highest_pagerank = [page_link for page_link, pr_value in catan_pr[:number_of_pages]]\n",
    "\n",
    "print(\"Pages with the highest PageRank:\", pages_with_highest_pagerank)\n",
    "\n",
    "G_sub_catan = G_catan.subgraph(pages_with_highest_pagerank)\n",
    "\n",
    "for t in networkx_pagerank(G_sub_catan):\n",
    "    print(t)\n",
    "    \n",
    "nx.draw(G_sub_catan, with_labels=True, node_size=60, font_size=8) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 - Analysis of the subset of pages about building costs [4p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"catan_building_costs.jpg\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_pages = [\n",
    "    '/wiki/Lumber', '/wiki/Brick', '/wiki/Wool', '/wiki/Grain', '/wiki/Ore', # Resources\n",
    "    '/wiki/Road', '/wiki/Settlement', '/wiki/City', '/wiki/Development_card' # Buildings (and \"build-able\" Development card)\n",
    "]\n",
    "\n",
    "G_sub_buildings = G_catan.subgraph(interesting_pages).copy()\n",
    "\n",
    "display(pd.DataFrame(nx.adjacency_matrix(G_sub_buildings).todense(), index=list(G_sub_buildings.nodes), columns=list(G_sub_buildings.nodes)))\n",
    "\n",
    "for t in networkx_pagerank(G_sub_buildings):\n",
    "    print(t)\n",
    "    \n",
    "nx.draw(G_sub_buildings, with_labels=True, node_size=60, font_size=8) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer the questions:**\n",
    "\n",
    "1. **[2p]** What is the reason for *City*'s advantage over *Settlement*? Take into account how the PageRank value is calculated\n",
    "2. **[2p]** Why are *Lumber* and *Brick* rated higher than other resources (*Wool*, *Ore*, *Grain*)? Take into account how the PageRank value is calculated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 - Analysis of the subset of pages about resources and hexes [5p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"catan_hexes_resources.jpg\" alt=\"drawing\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "interesting_pages = [\n",
    "    '/wiki/Hex', '/wiki/Resource_card', # A place from which to get a resource, Resource\n",
    "    '/wiki/Forest', '/wiki/Lumber', \n",
    "    '/wiki/Hill', '/wiki/Brick',\n",
    "    '/wiki/Pasture', '/wiki/Wool', \n",
    "    '/wiki/Field', '/wiki/Grain', \n",
    "    '/wiki/Mountain', '/wiki/Ore',\n",
    "]\n",
    "\n",
    "G_sub_res = G_catan.subgraph(interesting_pages)\n",
    "\n",
    "display(pd.DataFrame(nx.adjacency_matrix(G_sub_res).todense(), index=list(G_sub_res.nodes), columns=list(G_sub_res.nodes)))\n",
    "\n",
    "for t in networkx_pagerank(G_sub_res):\n",
    "    print(t)\n",
    "\n",
    "nx.draw(G_sub_res, with_labels=True, node_size=60, font_size=8) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer the questions:**\n",
    "\n",
    "1. **[2p]** Why are the PageRank values for the *Pasture-Wool* pair lower than for other resource's pairs (e.g. *Mountain-Ore*)? What changes to the structure of the graph will make them have comparable PageRank values?\n",
    "2. **[3p]** Replace *'/wiki/Hex'* with *'/wiki/Resource_hex'*. Try to explain why the PageRank values changed a lot for each group of pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tram stops graph in Poznań\n",
    "\n",
    "The scripts used for scraping are in the *scraper.ipynb* file.\n",
    "\n",
    "Connections between the tram stops come from the ZTM Poznań website: https://www.ztm.poznan.pl/pl/rozklad-jazdy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tram_stops.pickle', 'rb') as handle:\n",
    "    d = pickle.load(handle)\n",
    "\n",
    "G_tram = nx.DiGraph(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(G_tram.nodes)\n",
    "nx.draw(G_tram, with_labels=False, node_size=60, font_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5 - Test tram stops PageRank with different alpha values [2p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for alpha in [0.0, 0.1, 0.25, 0.5, 0.75, 0.9, 0.99, 1.0]:\n",
    "    print('ALPHA:', alpha)\n",
    "    for tram_stop in stochastic_matrix_pagerank(G_tram, alpha)[:5]:\n",
    "        print(tram_stop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer the question:**\n",
    "\n",
    "1. **[2p]** Try to explain why, as the $\\alpha$ value increases, the differences between the PageRank values for the *best* tram stops also increase?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6 - Subset of tram stops [6p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_stops = [\n",
    "    'Ogrody', 'Żeromskiego', 'Polna', 'Rynek Jeżycki', 'Kraszewskiego', 'Stare Zoo', 'Most Dworcowy',\n",
    "    'Bałtyk', 'Rondo Kaponiera', 'Bukowska', 'Matejki', 'Wojskowa', 'Ostroroga', 'Rondo Nowaka-Jeziorańskiego', \n",
    "    'Arena', 'Most Teatralny', 'Poznańska', 'Fredry', 'Zamek', 'Dworzec Zachodni', 'Most Dworcowy', 'Poznań Główny',\n",
    "]\n",
    "\n",
    "G_sub_tram = G_tram.subgraph(interesting_stops)\n",
    "\n",
    "display(pd.DataFrame(nx.adjacency_matrix(G_sub_tram).todense(), index=list(G_sub_tram.nodes), columns=list(G_sub_tram.nodes)))\n",
    "\n",
    "for t in networkx_pagerank(G_sub_tram):\n",
    "    print(t)\n",
    "\n",
    "nx.draw(G_sub_tram, with_labels=True, node_size=60, font_size=8) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** *Wojskowa* stop is an interesting case because it is available only in one direction of tram traffic\n",
    "\n",
    "**Answer the question:**\n",
    "\n",
    "\n",
    "1. **[2p]** Why does *Żeromskiego* have a comparable (even slightly higher) PageRank than *Most Dworcowy*, even though the latter has more neighbors in the graph?\n",
    "\n",
    "2. **[4p]** Suggest a modification of the PageRank algorithm that would take into account the number of lines that pass between adjacent stops. Describe which elements of the algorithm you would modify for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7 - TrustRank algorithm implementation [3p]\n",
    "\n",
    "Modify the PageRank implementation from the *stochastic matrix approach*. The only change from the PageRank implementation is the assumption that in TrustRank a *random jump* to *any* page always ends in one of the *trusted* pages. For this reason, it is also necessary to provide a list of trusted nodes. Modify the mathematical formula and the algorithm implementation in such way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def trustrank(graph: nx.DiGraph, trusted_nodes: list, alpha: float = 0.85, epsilon: float = 0.0000001) -> list:\n",
    "#     ...\n",
    "\n",
    "trustrank(G_random, [0, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "G_trustrank = nx.DiGraph()\n",
    "\n",
    "G_trustrank.add_nodes_from(range(7))\n",
    "\n",
    "G_trustrank.add_edge(0, 1)\n",
    "G_trustrank.add_edge(2, 1)\n",
    "G_trustrank.add_edge(3, 1)\n",
    "G_trustrank.add_edge(4, 1)\n",
    "G_trustrank.add_edge(1, 5)\n",
    "G_trustrank.add_edge(5, 2)\n",
    "G_trustrank.add_edge(5, 6)\n",
    "G_trustrank.add_edge(6, 0)\n",
    "G_trustrank.add_edge(6, 2)\n",
    "G_trustrank.add_edge(0, 3)\n",
    "G_trustrank.add_edge(6, 4)\n",
    "    \n",
    "print(G_trustrank.nodes)\n",
    "print(nx.adjacency_matrix(G_trustrank).todense())\n",
    "nx.draw(G_trustrank, with_labels=True)\n",
    "\n",
    "# trustrank(G_trustrank, [3, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8 - TrustRank example [4p]\n",
    "\n",
    "For the *G_trustrank* graph above, assume that good pages are 3 and 4.\n",
    "\n",
    "**Answer the questions:**\n",
    "\n",
    "1. **[2p]** Why did the *trusted* nodes (3, 4) have one of the lowest TrustRank values in the graph?\n",
    "2. **[2p]** What should be done to strengthen their importance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9 - HITS algorithm implementation [5p]\n",
    "\n",
    "Implement the **HITS** algorithm. You can choose whether you want to use the iterative version or use the eigenvector approach. Return results as two lists of tuples (similar to PageRank and TrustRank, but in two separate lists - **authorities** and **hubs**). For an iterative approach, normalize the vectors after each iteration (sum of values equals 1).\n",
    "\n",
    "**Hint:** update the values of both vectors *simultaneously*. Use the *hubs* and *authorities* values from the previous iteration to update both vectors. Don't use an updated *hubs* vector to update *authorities* during the same iteration or vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hits(graph: nx.DiGraph, epsilon: float = 0.0000001) -> list:\n",
    "#     ...\n",
    "\n",
    "hits(G_dead_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10 - HITS analysis [5p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interesting_pages = [\n",
    "    '/wiki/Hex', '/wiki/Resource_card', # A place from which to get a resource, Resource\n",
    "    '/wiki/Forest', '/wiki/Lumber', \n",
    "    '/wiki/Hill', '/wiki/Brick',\n",
    "    '/wiki/Pasture', '/wiki/Wool', \n",
    "    '/wiki/Field', '/wiki/Grain', \n",
    "    '/wiki/Mountain', '/wiki/Ore',\n",
    "]\n",
    "\n",
    "G_sub_res = G_catan.subgraph(interesting_pages)\n",
    "\n",
    "nx.draw(G_sub_res, with_labels=True, node_size=60, font_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits(G_sub_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer the question:**\n",
    "\n",
    "1. **[2p]** Check the HITS values in the chart above, then change the *Hex* to *Resource_hex* once again. How did this affect the results and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(G_sub_tram, with_labels=True, node_size=60, font_size=8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits(G_sub_tram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer the question:**\n",
    "\n",
    "2. **[3p]** Why are the results for *authorities* and *hubs* very similar?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
