{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you have the clips in data folder. They should be called:\n",
    "- `1.MOV`\n",
    "- `2.MOV`\n",
    "- `3.MOV`\n",
    "- `MEDIUM_1.MOV`\n",
    "- `MEDIUM_2.MOV`\n",
    "- `MEDIUM_3.MOV`\n",
    "- `HARD_1.MOV`\n",
    "- `HARD_2.MOV`\n",
    "- `HARD_3.MOV`\n",
    "- `test.mp4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "clips = [\n",
    "    '1.MOV',\n",
    "    '2.MOV',\n",
    "    '3.MOV',\n",
    "    'MEDIUM_1.MOV',\n",
    "    'MEDIUM_2.MOV',\n",
    "    'MEDIUM_3.MOV',\n",
    "    'HARD_1.MOV',\n",
    "    'HARD_2.MOV',\n",
    "    'HARD_3.MOV',\n",
    "    'test.mp4',\n",
    "]\n",
    "\n",
    "clips = [f'data/{clip}' for clip in clips]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(a):\n",
    "    a = a.clip(0, 255).astype(\"uint8\")\n",
    "    if a.ndim == 3:\n",
    "        if a.shape[2] == 4:\n",
    "            a = cv2.cvtColor(a, cv2.COLOR_BGRA2RGBA)\n",
    "        else:\n",
    "            a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
    "    display(PIL.Image.fromarray(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video(path):\n",
    "    cap = cv2.VideoCapture(path)\n",
    "    if cap.isOpened():\n",
    "        print('Opened the file successfully.')\n",
    "\n",
    "    print(f\"File name: {path}\")\n",
    "    # Height and width of the video\n",
    "    height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "    width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "\n",
    "    print(f\"Height: {height}, Width: {width}\")\n",
    "\n",
    "    # Number of frames in the video\n",
    "    FPS = cap.get(cv2.CAP_PROP_FPS)\n",
    "    print(f\"FPS: {FPS}\")\n",
    "\n",
    "    return cap, int(height), int(width), FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened the file successfully.\n",
      "File name: data/test.mp4\n",
      "Height: 1280.0, Width: 720.0\n",
      "FPS: 25.0\n"
     ]
    }
   ],
   "source": [
    "test_video, test_height, test_width, test_FPS = load_video(clips[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_clip_foreground = cv2.VideoWriter(\n",
    "    \"test_clip_foreground.avi\",\n",
    "    cv2.VideoWriter_fourcc(*\"HEVC\"),\n",
    "    test_FPS,\n",
    "    (int(test_width), int(test_height)),\n",
    "    0,\n",
    ")\n",
    "\n",
    "foreground_knn = cv2.createBackgroundSubtractorKNN(detectShadows=False)\n",
    "\n",
    "test_video.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "\n",
    "while test_video.isOpened():\n",
    "    ret, frame = test_video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    first_clip_foreground.write(foreground_knn.apply(frame))\n",
    "\n",
    "first_clip_foreground.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -hide_banner -loglevel error -i test_clip_foreground.avi -y test_clip_foreground.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# close test video\n",
    "test_video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened the file successfully.\n",
      "File name: data/2.MOV\n",
      "Height: 1920.0, Width: 1080.0\n",
      "FPS: 29.97002997002997\n"
     ]
    }
   ],
   "source": [
    "test_video, test_height, test_width, test_FPS = load_video(clips[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proper_opening(img, struct):\n",
    "  transformed = cv2.morphologyEx(\n",
    "      cv2.morphologyEx(\n",
    "          cv2.morphologyEx(img, cv2.MORPH_CLOSE, struct), cv2.MORPH_OPEN, struct\n",
    "      ), cv2.MORPH_CLOSE, struct\n",
    "  )\n",
    "\n",
    "  return np.min(np.stack((transformed, img), axis=2), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "input_file_path = clips[1]  # Replace \"your_input_video.mov\" with your input video file path\n",
    "output_file_path = \"test_red_clip.avi\"\n",
    "\n",
    "test_video = cv2.VideoCapture(input_file_path)\n",
    "\n",
    "if not test_video.isOpened():\n",
    "    print(\"Error: Could not open the video file.\")\n",
    "    exit()\n",
    "\n",
    "# Get video properties\n",
    "test_FPS = int(test_video.get(cv2.CAP_PROP_FPS))\n",
    "test_width = int(test_video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "test_height = int(test_video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"DIVX\")\n",
    "test_red_clip = cv2.VideoWriter(output_file_path, fourcc, test_FPS, (test_width, test_height))\n",
    "\n",
    "frame_number = 0\n",
    "while test_video.isOpened():\n",
    "    ret, frame = test_video.read()\n",
    "    frame_number += 1\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        print(frame_number)\n",
    "        break  # Exit the loop when no frames are retrieved\n",
    "    \n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Range of red color in HSV\n",
    "    lower_red = np.array([0, 100, 100])\n",
    "    upper_red = np.array([10, 255, 255])\n",
    "    lower_blue = np.array([110, 50, 50])\n",
    "    upper_blue = np.array([130, 255, 255])\n",
    "\n",
    "    # Threshold the HSV image to get only red or blue colors\n",
    "    mask_red = cv2.inRange(hsv, lower_red, upper_red)\n",
    "    mask_blue = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "\n",
    "    # Combine masks\n",
    "    mask = cv2.bitwise_or(mask_red, mask_blue)\n",
    "    \n",
    "    # apply proper opening \n",
    "    mask = proper_opening(mask, np.ones((11, 11), np.uint8))\n",
    "    # dilate mask to fill in holes\n",
    "    mask = cv2.dilate(mask, np.ones((7, 7), np.uint8), iterations=3)\n",
    "\n",
    "\n",
    "    # Bitwise-AND mask and original image\n",
    "    res = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "    test_red_clip.write(res)\n",
    "\n",
    "test_video.release()  # Release the video capture\n",
    "test_red_clip.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -hide_banner -loglevel error -i test_red_clip.avi -y test_red_clip.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened the file successfully.\n",
      "File name: data/3.MOV\n",
      "Height: 1920.0, Width: 1080.0\n",
      "FPS: 29.97002997002997\n",
      "Can't receive frame (stream end?). Exiting ...\n",
      "1906\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "input_file_path = clips[2]\n",
    "output_file_path = \"test_red_clip.avi\"\n",
    "\n",
    "test_video, test_height, test_width, test_FPS = load_video(input_file_path)\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"DIVX\")\n",
    "test_red_clip = cv2.VideoWriter(\n",
    "    output_file_path, \n",
    "    fourcc, \n",
    "    test_FPS, \n",
    "    (test_width, test_height),\n",
    "    )\n",
    "\n",
    "frame_number = 0\n",
    "while test_video.isOpened():\n",
    "    ret, frame = test_video.read()\n",
    "    frame_number += 1\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        print(frame_number)\n",
    "        break  # Exit the loop when no frames are retrieved\n",
    "    \n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Range of colors in HSV\n",
    "    lower_red = np.array([0, 100, 100])\n",
    "    upper_red = np.array([12, 255, 255])\n",
    "    lower_blue = np.array([98, 50, 50])\n",
    "    upper_blue = np.array([118, 255, 255])\n",
    "    lower_black = np.array([0, 0, 0])\n",
    "    upper_black = np.array([255, 255, 30])\n",
    "\n",
    "    # Threshold the HSV image to get only predefined colors\n",
    "    mask_red = cv2.inRange(hsv, lower_red, upper_red)\n",
    "    mask_blue = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "    mask_black = cv2.inRange(hsv, lower_black, upper_black)\n",
    "\n",
    "    # Combine masks\n",
    "    mask = cv2.bitwise_or(mask_red, mask_blue)\n",
    "    mask = cv2.bitwise_or(mask, mask_black)\n",
    "    \n",
    "    # apply proper opening \n",
    "    mask = proper_opening(mask, np.ones((9, 9), np.uint8))\n",
    "    # dilate mask to fill in holes\n",
    "    mask = cv2.dilate(mask, np.ones((3, 3), np.uint8), iterations=3)\n",
    "\n",
    "\n",
    "    # Find contours and draw bounding boxes around detected elements\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Draw bounding boxes on original frame\n",
    "    for contour in contours:\n",
    "        if cv2.contourArea(contour) < 1500 or cv2.contourArea(contour) > 50000:\n",
    "            continue\n",
    "            \n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        cv2.rectangle(frame, (x,y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        if np.sum(mask_blue[y:y+h, x:x+w]) > np.sum(mask_red[y:y+h, x:x+w]):\n",
    "            cv2.putText(frame, 'Team Blue', (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2)\n",
    "        elif np.sum(mask_blue[y:y+h, x:x+w]) < np.sum(mask_red[y:y+h, x:x+w]):\n",
    "            cv2.putText(frame, 'Team Red', (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "        else:\n",
    "            cv2.putText(frame, 'Assasin', (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "            \n",
    "\n",
    "    test_red_clip.write(frame)\n",
    "\n",
    "test_video.release()  # Release the video capture\n",
    "test_red_clip.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -hide_banner -loglevel error -i test_red_clip.avi -y test_clip.mp4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:**\n",
    "- Add filter for the hand, remove it from the color mask.\n",
    "- write separate bounding box for the hand.\n",
    "- fix HSV values for colors, add grey and black.\n",
    "- For grey, it possible we'll need to take some pictures of the cards and compare them to the video this way.\n",
    "- try to concatenate overlapping bounding boxes. [Stack Overflow](https://stackoverflow.com/questions/57258173/opencv-join-contours-when-rectangle-overlaps-another-rect)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
