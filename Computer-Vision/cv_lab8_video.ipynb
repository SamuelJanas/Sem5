{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "S_r0j8Xuqsga"
      },
      "source": [
        "# Computer vision - Lab 8\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qVWBS5p-r5j9"
      },
      "source": [
        "## Agenda"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cd2FzMMMr9kr"
      },
      "source": [
        "- introduction to the camera and its parameters\n",
        "- advanced image processing techniques,\n",
        "- understanding the scene as schemes, objects and optical effects,\n",
        "- advanced film processing techniques,\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WMJXpBTXtET5"
      },
      "source": [
        "## Helpers"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WfiyoH2V2Htn"
      },
      "source": [
        "### Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XE5KwNqA3Ots"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import PIL\n",
        "import os\n",
        "import sys\n",
        "import glob\n",
        "import random\n",
        "\n",
        "from pprint import pprint\n",
        "from ipywidgets import Video\n",
        "\n",
        "from PIL import Image\n",
        "from PIL.ExifTags import TAGS"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pmmZh-IZ3o43"
      },
      "source": [
        "### Datasets\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "33K8aecMdVem"
      },
      "source": [
        "* a set of stereoscopic images for the calibration of camera parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zy8FHINaHJ2Q",
        "outputId": "f4738eeb-d21e-4247-fb3e-7910e95c14c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cam_cal/left01.jpg  100%[===================>]  27.25K  --.-KB/s    in 0.001s  \n",
            "cam_cal/left02.jpg  100%[===================>]  27.94K  --.-KB/s    in 0.001s  \n",
            "cam_cal/left03.jpg  100%[===================>]  28.86K  --.-KB/s    in 0.001s  \n",
            "cam_cal/left04.jpg  100%[===================>]  24.56K  --.-KB/s    in 0.002s  \n",
            "cam_cal/left05.jpg  100%[===================>]  28.07K  --.-KB/s    in 0.001s  \n",
            "cam_cal/left06.jpg  100%[===================>]  27.86K  --.-KB/s    in 0.002s  \n",
            "cam_cal/left07.jpg  100%[===================>]  29.16K  --.-KB/s    in 0.003s  \n",
            "cam_cal/left08.jpg  100%[===================>]  28.02K  --.-KB/s    in 0.001s  \n",
            "cam_cal/left09.jpg  100%[===================>]  26.61K  --.-KB/s    in 0.003s  \n",
            "cam_cal/left11.jpg  100%[===================>]  27.10K  --.-KB/s    in 0.005s  \n",
            "cam_cal/left12.jpg  100%[===================>]  25.00K  --.-KB/s    in 0s      \n",
            "cam_cal/left13.jpg  100%[===================>]  27.47K  --.-KB/s    in 0.001s  \n",
            "cam_cal/left14.jpg  100%[===================>]  27.22K  --.-KB/s    in 0.001s  \n",
            "cam_cal/right01.jpg 100%[===================>]  26.44K  --.-KB/s    in 0.002s  \n",
            "cam_cal/right02.jpg 100%[===================>]  26.62K  --.-KB/s    in 0.006s  \n",
            "cam_cal/right03.jpg 100%[===================>]  27.98K  --.-KB/s    in 0.001s  \n",
            "cam_cal/right04.jpg 100%[===================>]  23.74K  --.-KB/s    in 0.001s  \n",
            "cam_cal/right05.jpg 100%[===================>]  25.69K  --.-KB/s    in 0.002s  \n",
            "cam_cal/right06.jpg 100%[===================>]  27.20K  --.-KB/s    in 0.001s  \n",
            "cam_cal/right07.jpg 100%[===================>]  27.76K  --.-KB/s    in 0.002s  \n",
            "cam_cal/right08.jpg 100%[===================>]  27.63K  --.-KB/s    in 0.001s  \n",
            "cam_cal/right09.jpg 100%[===================>]  25.31K  --.-KB/s    in 0.002s  \n",
            "cam_cal/right11.jpg 100%[===================>]  25.12K  --.-KB/s    in 0.001s  \n",
            "cam_cal/right12.jpg 100%[===================>]  24.21K  --.-KB/s    in 0.002s  \n",
            "cam_cal/right13.jpg 100%[===================>]  26.74K  --.-KB/s    in 0.001s  \n",
            "cam_cal/right14.jpg 100%[===================>]  25.14K  --.-KB/s    in 0.002s  \n"
          ]
        }
      ],
      "source": [
        "!rm -rf ./cam_cal\n",
        "!mkdir cam_cal\n",
        "!wget -O cam_cal/left01.jpg https://github.com/opencv/opencv/raw/master/samples/data/left01.jpg -q --show-progress\n",
        "!wget -O cam_cal/left02.jpg https://github.com/opencv/opencv/raw/master/samples/data/left02.jpg -q --show-progress\n",
        "!wget -O cam_cal/left03.jpg https://github.com/opencv/opencv/raw/master/samples/data/left03.jpg -q --show-progress\n",
        "!wget -O cam_cal/left04.jpg https://github.com/opencv/opencv/raw/master/samples/data/left04.jpg -q --show-progress\n",
        "!wget -O cam_cal/left05.jpg https://github.com/opencv/opencv/raw/master/samples/data/left05.jpg -q --show-progress\n",
        "!wget -O cam_cal/left06.jpg https://github.com/opencv/opencv/raw/master/samples/data/left06.jpg -q --show-progress\n",
        "!wget -O cam_cal/left07.jpg https://github.com/opencv/opencv/raw/master/samples/data/left07.jpg -q --show-progress\n",
        "!wget -O cam_cal/left08.jpg https://github.com/opencv/opencv/raw/master/samples/data/left08.jpg -q --show-progress\n",
        "!wget -O cam_cal/left09.jpg https://github.com/opencv/opencv/raw/master/samples/data/left09.jpg -q --show-progress\n",
        "!wget -O cam_cal/left11.jpg https://github.com/opencv/opencv/raw/master/samples/data/left11.jpg -q --show-progress\n",
        "!wget -O cam_cal/left12.jpg https://github.com/opencv/opencv/raw/master/samples/data/left12.jpg -q --show-progress\n",
        "!wget -O cam_cal/left13.jpg https://github.com/opencv/opencv/raw/master/samples/data/left13.jpg -q --show-progress\n",
        "!wget -O cam_cal/left14.jpg https://github.com/opencv/opencv/raw/master/samples/data/left14.jpg -q --show-progress\n",
        "\n",
        "!wget -O cam_cal/right01.jpg https://github.com/opencv/opencv/raw/master/samples/data/right01.jpg -q --show-progress\n",
        "!wget -O cam_cal/right02.jpg https://github.com/opencv/opencv/raw/master/samples/data/right02.jpg -q --show-progress\n",
        "!wget -O cam_cal/right03.jpg https://github.com/opencv/opencv/raw/master/samples/data/right03.jpg -q --show-progress\n",
        "!wget -O cam_cal/right04.jpg https://github.com/opencv/opencv/raw/master/samples/data/right04.jpg -q --show-progress\n",
        "!wget -O cam_cal/right05.jpg https://github.com/opencv/opencv/raw/master/samples/data/right05.jpg -q --show-progress\n",
        "!wget -O cam_cal/right06.jpg https://github.com/opencv/opencv/raw/master/samples/data/right06.jpg -q --show-progress\n",
        "!wget -O cam_cal/right07.jpg https://github.com/opencv/opencv/raw/master/samples/data/right07.jpg -q --show-progress\n",
        "!wget -O cam_cal/right08.jpg https://github.com/opencv/opencv/raw/master/samples/data/right08.jpg -q --show-progress\n",
        "!wget -O cam_cal/right09.jpg https://github.com/opencv/opencv/raw/master/samples/data/right09.jpg -q --show-progress\n",
        "!wget -O cam_cal/right11.jpg https://github.com/opencv/opencv/raw/master/samples/data/right11.jpg -q --show-progress\n",
        "!wget -O cam_cal/right12.jpg https://github.com/opencv/opencv/raw/master/samples/data/right12.jpg -q --show-progress\n",
        "!wget -O cam_cal/right13.jpg https://github.com/opencv/opencv/raw/master/samples/data/right13.jpg -q --show-progress\n",
        "!wget -O cam_cal/right14.jpg https://github.com/opencv/opencv/raw/master/samples/data/right14.jpg -q --show-progress"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "P24-i9f1dY7d"
      },
      "source": [
        "* stereoscopic images from the Middlesbury dataset  [link](https://vision.middlebury.edu/stereo/data/scenes2006/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjXveCCOZSz7",
        "outputId": "16118bf1-fd8b-4b12-e17c-8f3ca2fd12fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=17g5lfQkqXSIfJQLA2UHBZdoiD5PvV_tu\n",
            "To: /content/right-aloe-image.png\n",
            "100% 208k/208k [00:00<00:00, 3.44MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=176GBMR2o4_sYaPIo8Sdr3izTf4lilfVP\n",
            "To: /content/left-aloe-image.png\n",
            "100% 208k/208k [00:00<00:00, 3.40MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 17g5lfQkqXSIfJQLA2UHBZdoiD5PvV_tu\n",
        "!gdown --id 176GBMR2o4_sYaPIo8Sdr3izTf4lilfVP"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qjDeWVA9ddT1"
      },
      "source": [
        "* sudoku - a sample sudoku image from the OpenCV repository,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Am1kLIPdb_lX",
        "outputId": "b45b2492-0150-4712-e3f0-692b407cd11a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rsudoku.png            0%[                    ]       0  --.-KB/s               \rsudoku.png          100%[===================>] 244.84K  --.-KB/s    in 0.02s   \n"
          ]
        }
      ],
      "source": [
        "!wget -O sudoku.png https://raw.githubusercontent.com/opencv/opencv/master/samples/data/sudoku.png -q --show-progress"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Ez6EWllJdxVH"
      },
      "source": [
        "* skittles - skittles image from wikimedia.org"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wil_5ohZi4LJ",
        "outputId": "7701c52f-be6a-42a3-8b7c-47891495c445"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rskittles.jpg          0%[                    ]       0  --.-KB/s               \rskittles.jpg        100%[===================>] 766.67K  --.-KB/s    in 0.1s    \n"
          ]
        }
      ],
      "source": [
        "!wget -O skittles.jpg https://upload.wikimedia.org/wikipedia/commons/c/ca/Skittles-Louisiana-2003.jpg -q --show-progress"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LFtPC2vud0OR"
      },
      "source": [
        "* a frame from a football match between the Polish and England national teams and a fragment of the frame that will serve as a model for the pattern detection algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePjBbixlqKce",
        "outputId": "e8e9a0ac-d984-4185-a747-2473afed5de7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1D-GbfGKqn982VG43SSB62-PIiv0QXuoZ\n",
            "To: /content/pl_eng.png\n",
            "100% 853k/853k [00:00<00:00, 7.87MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=17jZaa3iQO78Bjgk1W3EYBFE7RXKQ7gcM\n",
            "To: /content/template.png\n",
            "100% 19.4k/19.4k [00:00<00:00, 31.2MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1D-GbfGKqn982VG43SSB62-PIiv0QXuoZ\n",
        "!gdown --id 17jZaa3iQO78Bjgk1W3EYBFE7RXKQ7gcM"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OaH-H8y-unbO"
      },
      "source": [
        "* parameters of the Haar Cascade classifier for face and eye recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Ekybw3kuiKS",
        "outputId": "814adcbd-65b6-4a8e-b012-30ad6e6f4c8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "haar_face.xml       100%[===================>] 660.85K  --.-KB/s    in 0.04s   \n",
            "haar_eye.xml        100%[===================>] 587.56K  --.-KB/s    in 0.04s   \n",
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=10b2rtAv_blqJT1VsEgeOE7GbhZcgLdTV\n",
            "To: /content/face.jpeg\n",
            "100% 433k/433k [00:00<00:00, 4.78MB/s]\n"
          ]
        }
      ],
      "source": [
        "!wget -O haar_face.xml https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_alt.xml -q --show-progress\n",
        "!wget -O haar_eye.xml https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_eye_tree_eyeglasses.xml -q --show-progress\n",
        "\n",
        "!gdown --id 10b2rtAv_blqJT1VsEgeOE7GbhZcgLdTV"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Ig3jR-HLeGpd"
      },
      "source": [
        "* excerpt from a scientific article on generating robot movements based on music of various types ([link](https://www.youtube.com/watch?v=kHBLaw5nfzk)) - the robot is located at the Poznań University of Technology,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3vtJ92X49ky",
        "outputId": "123bd675-46c4-4df8-9a97-47bb67b79b54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1lJF5LX6m1KbgNGI2pJBQJVgEaU0VdUuF\n",
            "To: /content/anymal_cut.mp4\n",
            "100% 948k/948k [00:00<00:00, 8.10MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 1lJF5LX6m1KbgNGI2pJBQJVgEaU0VdUuF"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8hOQxINMeLuk"
      },
      "source": [
        "* video from the repository OpenCV,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFn8bChDNYlN",
        "outputId": "1b2fb122-c60b-4324-b51b-4634e27ef639"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\rslow_traffic_small.   0%[                    ]       0  --.-KB/s               \rslow_traffic_small. 100%[===================>]   1.92M  --.-KB/s    in 0.1s    \n"
          ]
        }
      ],
      "source": [
        "!wget -O slow_traffic_small.mp4 https://www.bogotobogo.com/python/OpenCV_Python/images/mean_shift_tracking/slow_traffic_small.mp4 -q --show-progress"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "gU9hoIeVeRlu"
      },
      "source": [
        "* images shot with different shutter speeds and containing the same subject. Images come from a dataset  [link](http://pages.cs.wisc.edu/~csverma/CS766_09/HDRI/hdr.html) (Chaman Singh Verma i Mon-Ju)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "msE5ryZvsCXF",
        "outputId": "85b99a8a-cb7a-42a7-dad7-686dacc3869d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "hdr.tar             100%[===================>]  41.76M  32.0MB/s    in 1.3s    \n"
          ]
        }
      ],
      "source": [
        "!mkdir -p hdr\n",
        "!wget -O hdr.tar http://pages.cs.wisc.edu/~csverma/CS766_09/HDRI/DataSet/Set3/set3images.tar -q --show-progress\n",
        "!tar -xf hdr.tar -C ./hdr"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LuNNirnReZSh"
      },
      "source": [
        "* clip of the English League match between Manchester United and Chelsea London."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7umbx6z8Jl3",
        "outputId": "11ccad95-74ec-48c2-8843-dbf393b75473"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gdown/cli.py:121: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=16-H5SnEloiRgnSj_qtKNy0BTkJQZXi6c\n",
            "To: /content/free_kick.mp4\n",
            "100% 510k/510k [00:00<00:00, 5.38MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --id 16-H5SnEloiRgnSj_qtKNy0BTkJQZXi6c"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "b3desh1dBMaw"
      },
      "source": [
        "### Visualization\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCHL_RVqunsJ"
      },
      "outputs": [],
      "source": [
        "def imshow(a):\n",
        "    a = a.clip(0, 255).astype(\"uint8\")\n",
        "    if a.ndim == 3:\n",
        "        if a.shape[2] == 4:\n",
        "            a = cv2.cvtColor(a, cv2.COLOR_BGRA2RGBA)\n",
        "        else:\n",
        "            a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
        "    display(PIL.Image.fromarray(a))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XFgmkFPUn3IN"
      },
      "source": [
        "# Video"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bGu46uq7nn9L"
      },
      "source": [
        "## Background removal"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3rNVyf8gJka"
      },
      "source": [
        "Due to the computational requirements, the class of algorithms used in video processing is based on iterative provision of information and its use.\n",
        "\n",
        "One of the most important areas of work on video processing is detailing the background and moving elements.\n",
        "\n",
        "Two iterative background masking algorithms are presented below ([A Duality Based Approach for Realtime TV-L1\n",
        "Optical Flow](https://pequan.lip6.fr/~bereziat/cours/master/vision/papers/zach07.pdf)):\n",
        "- cv2.createBackgroundSubtractorKNN()\n",
        "- cv2.createBackgroundSubtractorMOG2()\n",
        "\n",
        "These algorithms **learn** from the successive frames of the video, describing the background based on how the pixel and its surroundings have changed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZNdNn4e5LGO",
        "outputId": "dc27d3a7-52b3-44b4-e163-c440aec3e898"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video loaded\n",
            "360 640\n",
            "30.0\n"
          ]
        }
      ],
      "source": [
        "anymal = cv2.VideoCapture(\"./anymal_cut.mp4\")\n",
        "if anymal.isOpened():\n",
        "    print(\"Video loaded\")\n",
        "\n",
        "anymal_width = int(anymal.get(3))\n",
        "anymal_height = int(anymal.get(4))\n",
        "\n",
        "print(anymal_height, anymal_width)\n",
        "\n",
        "anymal_fps = anymal.get(cv2.CAP_PROP_FPS)\n",
        "print(anymal_fps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175,
          "referenced_widgets": [
            "dee0d8f449dd40ee9fc9ddccf2617e15",
            "e38b7f8bf5a841e391c94c4c78f6c0ae"
          ]
        },
        "id": "nw5PyVb3KoKX",
        "outputId": "bf283509-ff9d-40ed-9baf-4b2a29f398e8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dee0d8f449dd40ee9fc9ddccf2617e15",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Video(value=b'\\x00\\x00\\x00 ftypisom\\x00\\x00\\x02\\x00isomiso2avc1mp41\\x00\\x00\\x00\\x08free\\x00\\x0e1\\x87mdat\\x00\\x…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "Video.from_file(\"anymal_cut.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nUbW9OBNvRdT"
      },
      "outputs": [],
      "source": [
        "anymal_foreground_knn = cv2.VideoWriter(\n",
        "    \"anymal_cut_foreground_knn.avi\",\n",
        "    cv2.VideoWriter_fourcc(*\"DIVX\"),\n",
        "    anymal_fps,\n",
        "    (anymal_width, anymal_height),\n",
        "    0,\n",
        ")\n",
        "anymal_foreground_mog2 = cv2.VideoWriter(\n",
        "    \"anymal_cut_foreground_mog2.avi\",\n",
        "    cv2.VideoWriter_fourcc(*\"DIVX\"),\n",
        "    anymal_fps,\n",
        "    (anymal_width, anymal_height),\n",
        "    0,\n",
        ")\n",
        "\n",
        "foreground_knn = cv2.createBackgroundSubtractorKNN()\n",
        "foreground_mog2 = cv2.createBackgroundSubtractorMOG2()\n",
        "\n",
        "anymal.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "while anymal.isOpened():\n",
        "    ret, frame = anymal.read()\n",
        "\n",
        "    if ret:\n",
        "        anymal_foreground_knn.write(foreground_knn.apply(frame))\n",
        "        anymal_foreground_mog2.write(foreground_mog2.apply(frame))\n",
        "    else:\n",
        "        break\n",
        "\n",
        "anymal_foreground_knn.release()\n",
        "anymal_foreground_mog2.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUdogKQRJT1H"
      },
      "outputs": [],
      "source": [
        "!ffmpeg -hide_banner -loglevel error -i anymal_cut_foreground_knn.avi -y anymal_cut_foreground_knn.mp4\n",
        "!ffmpeg -hide_banner -loglevel error -i anymal_cut_foreground_mog2.avi -y anymal_cut_foreground_mog2.mp4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSd8Lhh3EchI"
      },
      "outputs": [],
      "source": [
        "Video.from_file(\"anymal_cut_foreground_knn.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a55Oe7uYK6k4"
      },
      "outputs": [],
      "source": [
        "Video.from_file(\"anymal_cut_foreground_mog2.mp4\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Aucg-9fcn4EC"
      },
      "source": [
        "## Object tracking"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Y02V2GeNgPx2"
      },
      "source": [
        "In addition to the separation of static and dynamic elements from the background, one can also distinguish a class of object tracking algorithms.\n",
        "\n",
        "A big disadvantage of classic algorithms in this field is **the requirement to indicate the element that we want to track**. These algorithms only implement a tracking function, not a detection function.\n",
        "\n",
        "The basic algorithms include:\n",
        "- mean shift - an iterative algorithm that checks matches in the immediate vicinity of the current match and moves towards the best neighbor,\n",
        "- cam shift - modification of the mean shift algorithm, which also adjusts the environment (window / bounding box) in subsequent steps,\n",
        "- more advanced, also with the training phase:\n",
        "  - Boosting,\n",
        "  - MIL,\n",
        "  - KCF,\n",
        "  - TLF,\n",
        "  - MedianFlow,\n",
        "  - GOTURN,\n",
        "  - MOSSE,\n",
        "  - CSRT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cW_Om5CqNrYP",
        "outputId": "aed83754-1da2-4d04-f7c2-5df7d12ef66e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video loaded\n",
            "360 640\n",
            "29.97002997002997\n"
          ]
        }
      ],
      "source": [
        "traffic = cv2.VideoCapture(\"./slow_traffic_small.mp4\")\n",
        "if traffic.isOpened():\n",
        "    print(\"Video loaded\")\n",
        "\n",
        "traffic_width = int(traffic.get(3))\n",
        "traffic_height = int(traffic.get(4))\n",
        "\n",
        "print(traffic_height, traffic_width)\n",
        "\n",
        "traffic_fps = traffic.get(cv2.CAP_PROP_FPS)\n",
        "print(traffic_fps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "referenced_widgets": [
            "acff6537d67e4967ad4821d8f02b38dc"
          ]
        },
        "id": "0D88r2ZJNthK",
        "outputId": "ee80dbda-8e3d-4162-8d3b-e6810448ee37"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "acff6537d67e4967ad4821d8f02b38dc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Video(value=b'\\x00\\x00\\x00 ftypisom\\x00\\x00\\x02\\x00isomiso2avc1mp41\\x00\\x00\\x00\\x08free\\x00\\x1eD\\xe4mdat\\x00\\x…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "Video.from_file(\"./slow_traffic_small.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "E2yRx3LWvzkX"
      },
      "outputs": [],
      "source": [
        "traffic.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "ret, frame = traffic.read()\n",
        "x, y, w, h = 300, 200, 100, 50  # simply hardcoded the values\n",
        "track_window = (x, y, w, h)\n",
        "roi = frame[y : y + h, x : x + w]\n",
        "\n",
        "hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
        "mask = cv2.inRange(\n",
        "    hsv_roi, np.array((0.0, 60.0, 32.0)), np.array((180.0, 255.0, 255.0))\n",
        ")\n",
        "roi_hist = cv2.calcHist([hsv_roi], [0], mask, [180], [0, 180])\n",
        "cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
        "term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JTBMSEFtOXQf"
      },
      "outputs": [],
      "source": [
        "traffic_track = cv2.VideoWriter(\n",
        "    \"./slow_traffic_small_meanshift.avi\",\n",
        "    cv2.VideoWriter_fourcc(*\"DIVX\"),\n",
        "    traffic_fps,\n",
        "    (traffic_width, traffic_height),\n",
        ")\n",
        "\n",
        "traffic.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "while traffic.isOpened():\n",
        "    ret, frame = traffic.read()\n",
        "\n",
        "    if ret:\n",
        "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "        dst = cv2.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)\n",
        "        ret, track_window = cv2.meanShift(dst, track_window, term_crit)\n",
        "        x, y, w, h = track_window\n",
        "        traffic_track.write(cv2.rectangle(frame, (x, y), (x + w, y + h), 255, 2))\n",
        "    else:\n",
        "        break\n",
        "\n",
        "traffic_track.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3JNA1qBNPDyo"
      },
      "outputs": [],
      "source": [
        "!ffmpeg -hide_banner -loglevel error -i slow_traffic_small_meanshift.avi -y slow_traffic_small_meanshift.mp4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDvqTjVDPSqK"
      },
      "outputs": [],
      "source": [
        "Video.from_file(\"./slow_traffic_small_meanshift.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kO_88IOkv38c"
      },
      "outputs": [],
      "source": [
        "traffic.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "ret, frame = traffic.read()\n",
        "x, y, w, h = 300, 200, 100, 50  # simply hardcoded the values\n",
        "track_window = (x, y, w, h)\n",
        "roi = frame[y : y + h, x : x + w]\n",
        "\n",
        "hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
        "mask = cv2.inRange(\n",
        "    hsv_roi, np.array((0.0, 60.0, 32.0)), np.array((180.0, 255.0, 255.0))\n",
        ")\n",
        "roi_hist = cv2.calcHist([hsv_roi], [0], mask, [180], [0, 180])\n",
        "cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
        "term_crit = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CEw_-Y4QFjB"
      },
      "outputs": [],
      "source": [
        "traffic_track = cv2.VideoWriter(\n",
        "    \"./slow_traffic_small_camshift.avi\",\n",
        "    cv2.VideoWriter_fourcc(*\"DIVX\"),\n",
        "    traffic_fps,\n",
        "    (traffic_width, traffic_height),\n",
        ")\n",
        "\n",
        "traffic.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "while traffic.isOpened():\n",
        "    ret, frame = traffic.read()\n",
        "\n",
        "    if ret:\n",
        "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
        "        dst = cv2.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)\n",
        "        ret, track_window = cv2.CamShift(dst, track_window, term_crit)\n",
        "        pts = np.int0(cv2.boxPoints(ret))\n",
        "        traffic_track.write(cv2.polylines(frame, [pts], True, 255, 2))\n",
        "    else:\n",
        "        break\n",
        "\n",
        "traffic_track.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8nCB5I9QmU-"
      },
      "outputs": [],
      "source": [
        "!ffmpeg -hide_banner -loglevel error -i slow_traffic_small_camshift.avi -y slow_traffic_small_camshift.mp4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18SZlGLlQnng"
      },
      "outputs": [],
      "source": [
        "Video.from_file(\"./slow_traffic_small_camshift.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4_5VaeV9tWt"
      },
      "outputs": [],
      "source": [
        "free_kick = cv2.VideoCapture(\"free_kick.mp4\")\n",
        "if free_kick.isOpened():\n",
        "    print(\"Video loaded\")\n",
        "\n",
        "free_kick_width = int(free_kick.get(3))\n",
        "free_kick_height = int(free_kick.get(4))\n",
        "\n",
        "print(free_kick_height, free_kick_width)\n",
        "\n",
        "free_kick_fps = free_kick.get(cv2.CAP_PROP_FPS)\n",
        "print(free_kick_fps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zGl4KGOD_7-k"
      },
      "outputs": [],
      "source": [
        "def create_tracker(tracker_type):\n",
        "    tracker_types = [\n",
        "        \"BOOSTING\",\n",
        "        \"MIL\",\n",
        "        \"KCF\",\n",
        "        \"TLD\",\n",
        "        \"MEDIANFLOW\",\n",
        "        \"GOTURN\",\n",
        "        \"MOSSE\",\n",
        "        \"CSRT\",\n",
        "    ]\n",
        "\n",
        "    if tracker_type == \"BOOSTING\":\n",
        "        return cv2.TrackerBoosting_create()\n",
        "    if tracker_type == \"MIL\":\n",
        "        return cv2.TrackerMIL_create()\n",
        "    if tracker_type == \"KCF\":\n",
        "        return cv2.TrackerKCF_create()\n",
        "    if tracker_type == \"TLD\":\n",
        "        return cv2.TrackerTLD_create()\n",
        "    if tracker_type == \"MEDIANFLOW\":\n",
        "        return cv2.TrackerMedianFlow_create()\n",
        "    if tracker_type == \"GOTURN\":\n",
        "        return cv2.TrackerGOTURN_create()\n",
        "    if tracker_type == \"MOSSE\":\n",
        "        return cv2.TrackerMOSSE_create()\n",
        "    if tracker_type == \"CSRT\":\n",
        "        return cv2.TrackerCSRT_create()\n",
        "\n",
        "\n",
        "def draw_bbox(frame, bbox, color=(255, 255, 255)):\n",
        "    p1 = (int(bbox[0]), int(bbox[1]))\n",
        "    p2 = (int(bbox[0] + bbox[2]), int(bbox[1] + bbox[3]))\n",
        "    cv2.rectangle(frame, p1, p2, color, 2, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOEZDH_QBv2M"
      },
      "outputs": [],
      "source": [
        "free_kick.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "ret, frame = free_kick.read()\n",
        "\n",
        "player_bbox = (190, 260, 70, 100)\n",
        "gkeeper_bbox = (375, 55, 60, 80)\n",
        "\n",
        "draw_bbox(frame, player_bbox, (255, 0, 0))\n",
        "draw_bbox(frame, gkeeper_bbox, (255, 255, 0))\n",
        "\n",
        "imshow(frame)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91MiRXGwvTy8"
      },
      "outputs": [],
      "source": [
        "free_kick.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "ret, frame = free_kick.read()\n",
        "\n",
        "player_bbox = (190, 260, 70, 100)\n",
        "gkeeper_bbox = (375, 55, 60, 80)\n",
        "\n",
        "player_tracker = create_tracker(\"CSRT\")\n",
        "gkeeper_tracker = create_tracker(\"CSRT\")\n",
        "\n",
        "if player_tracker.init(frame, player_bbox):\n",
        "    print(\"Player tracking algorithm initiated at point:\", player_bbox)\n",
        "\n",
        "if gkeeper_tracker.init(frame, gkeeper_bbox):\n",
        "    print(\"Goalkeeper tracking algorithm initiated at point:\", gkeeper_bbox)\n",
        "\n",
        "free_kick_track = cv2.VideoWriter(\n",
        "    \"./free_kick_track.avi\",\n",
        "    cv2.VideoWriter_fourcc(*\"DIVX\"),\n",
        "    free_kick_fps,\n",
        "    (free_kick_width, free_kick_height),\n",
        ")\n",
        "\n",
        "free_kick.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "while free_kick.isOpened():\n",
        "    ret, frame = free_kick.read()\n",
        "\n",
        "    if ret:\n",
        "        ok, bbox = player_tracker.update(frame)\n",
        "        if ok:\n",
        "            draw_bbox(frame, bbox, (0, 255, 0))\n",
        "\n",
        "        ok, bbox = gkeeper_tracker.update(frame)\n",
        "        if ok:\n",
        "            draw_bbox(frame, bbox, (0, 255, 0))\n",
        "\n",
        "        free_kick_track.write(frame)\n",
        "    else:\n",
        "        break\n",
        "\n",
        "free_kick_track.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rpU9V9T-Ge2"
      },
      "outputs": [],
      "source": [
        "!ffmpeg -hide_banner -loglevel error -i free_kick_track.avi -y free_kick_track.mp4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5R8wqKJF-J8Y"
      },
      "outputs": [],
      "source": [
        "Video.from_file(\"./free_kick_track.mp4\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "m6AKfHqCoLMh"
      },
      "source": [
        "## Optical flow"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "G1P_KPC7gsqh"
      },
      "source": [
        "Object tracking requires that you recognize and know some kind of object that you want to track. For example, by following the players on the pitch, we know what they look like (we have a pattern). The general case of object tracking is optical motion tracking.\n",
        "\n",
        "For example, a soccer player can move forward. In the event that it is an attempt to kick the ball, the footballer will likely make a hand movement. Both the player (as an object) moved one way and the hands (as sub-objects) moved the other way.\n",
        "\n",
        "Optical motion tracking goes even lower and analyzes the pixels and their surroundings, firstly identifying characteristic points in the image and secondly tracking them as separate objects.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "945WzZw0IxS7"
      },
      "outputs": [],
      "source": [
        "traffic = cv2.VideoCapture(\"./slow_traffic_small.mp4\")\n",
        "if traffic.isOpened():\n",
        "    print(\"Video loaded!\")\n",
        "\n",
        "traffic_width = int(traffic.get(3))\n",
        "traffic_height = int(traffic.get(4))\n",
        "\n",
        "print(traffic_height, traffic_width)\n",
        "\n",
        "traffic_fps = traffic.get(cv2.CAP_PROP_FPS)\n",
        "print(traffic_fps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1ilusSIIzuV"
      },
      "outputs": [],
      "source": [
        "Video.from_file(\"./slow_traffic_small.mp4\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vd6LiqQXJCGK"
      },
      "outputs": [],
      "source": [
        "feature_params = dict(maxCorners=100, qualityLevel=0.3, minDistance=7, blockSize=7)\n",
        "lk_params = dict(\n",
        "    winSize=(15, 15),\n",
        "    maxLevel=2,\n",
        "    criteria=(cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03),\n",
        ")\n",
        "# Create some random colors\n",
        "color = np.random.randint(0, 255, (100, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSOsX5ZOJYCQ"
      },
      "outputs": [],
      "source": [
        "traffic.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "ret, old_frame = traffic.read()\n",
        "\n",
        "old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
        "p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
        "mask = np.zeros_like(old_frame)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wn1-LIxMI3yD"
      },
      "outputs": [],
      "source": [
        "traffic_optical_flow = cv2.VideoWriter(\n",
        "    \"./slow_traffic_small_optical_flow.avi\",\n",
        "    cv2.VideoWriter_fourcc(*\"DIVX\"),\n",
        "    traffic_fps,\n",
        "    (traffic_width, traffic_height),\n",
        ")\n",
        "\n",
        "traffic.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
        "while traffic.isOpened():\n",
        "    ret, frame = traffic.read()\n",
        "\n",
        "    if ret:\n",
        "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        p1, st, err = cv2.calcOpticalFlowPyrLK(\n",
        "            old_gray, frame_gray, p0, None, **lk_params\n",
        "        )\n",
        "        if p1 is not None:\n",
        "            good_new = p1[st == 1]\n",
        "            good_old = p0[st == 1]\n",
        "\n",
        "        for i, (new, old) in enumerate(zip(good_new, good_old)):\n",
        "            a, b = new.ravel()\n",
        "            c, d = old.ravel()\n",
        "            mask = cv2.line(\n",
        "                mask, (int(a), int(b)), (int(c), int(d)), color[i].tolist(), 2\n",
        "            )\n",
        "            frame = cv2.circle(frame, (int(a), int(b)), 5, color[i].tolist(), -1)\n",
        "\n",
        "        old_gray = frame_gray.copy()\n",
        "        p0 = good_new.reshape(-1, 1, 2)\n",
        "\n",
        "        traffic_optical_flow.write(cv2.add(frame, mask))\n",
        "    else:\n",
        "        break\n",
        "\n",
        "traffic_optical_flow.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzpqG4n7Kh4W"
      },
      "outputs": [],
      "source": [
        "!ffmpeg -hide_banner -loglevel error -i slow_traffic_small_optical_flow.avi -y slow_traffic_small_optical_flow.mp4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xS-U4FlQKl3-"
      },
      "outputs": [],
      "source": [
        "Video.from_file(\"./slow_traffic_small_optical_flow.mp4\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dee0d8f449dd40ee9fc9ddccf2617e15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VideoModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VideoModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VideoView",
            "autoplay": true,
            "controls": true,
            "format": "mp4",
            "height": "",
            "layout": "IPY_MODEL_e38b7f8bf5a841e391c94c4c78f6c0ae",
            "loop": true,
            "width": ""
          }
        },
        "e38b7f8bf5a841e391c94c4c78f6c0ae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
